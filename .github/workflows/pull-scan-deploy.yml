
name: CI/CD -> SonarQube -> Trivy -> EKS -> Apply Manifests

on:
  push:
    branches: [ "main" ]
  workflow_dispatch:
    inputs:
      image_tag:
        description: "Docker Hub image tag (default: latest)"
        required: false
        default: "latest"

env:
  IMAGE_REPO: devenops641/endhunger
  IMAGE_TAG: latest
  K8S_NAMESPACE: default
  K8S_DEPLOYMENT: endhunger
  K8S_CONTAINER: endhunger

jobs:
  deploy:
    runs-on: self-hosted

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set IMAGE_TAG
        run: |
          TAG="${{ github.event.inputs.image_tag }}"
          if [ -z "$TAG" ]; then TAG="latest"; fi
          echo "IMAGE_TAG=$TAG" >> "$GITHUB_ENV"
          echo "Using image: ${{ env.IMAGE_REPO }}:$TAG"

      # (Option A) Keep the action
      - name: Install kubectl
        uses: azure/setup-kubectl@v4
        with:
          version: 'v1.29.0'

      - name: Pull Docker image
        run: |
          echo "Pulling ${{ env.IMAGE_REPO }}:${{ env.IMAGE_TAG }}"
          docker pull ${{ env.IMAGE_REPO }}:${{ env.IMAGE_TAG }}

      - name: SonarQube Scan
        uses: SonarSource/sonarqube-scan-action@v2
        with:
          args: >
            -Dsonar.projectKey=endhunger
            -Dsonar.projectName=endhunger
            -Dsonar.sources=.
        env:
          SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}
          SONAR_HOST_URL: ${{ secrets.SONAR_HOST_URL }}

      # FIXED: use a valid Trivy Action tag
#      - name: Trivy Scan
#        uses: aquasecurity/trivy-action@0.33.1
#        with:
#          image-ref: ${{ env.IMAGE_REPO }}:${{ env.IMAGE_TAG }}
#          format: 'table'
#          exit-code: '1'
#          severity: 'CRITICAL,HIGH'

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}

      - name: Update kubeconfig
        run: |
          aws eks update-kubeconfig \
            --name ${{ secrets.EKS_CLUSTER_NAME }} \
            --region ${{ secrets.AWS_REGION }}
          kubectl version --client
          kubectl get nodes -o wide
          kubectl get pods --all-namespace

      - name: Update Deployment image
        run: |
          echo "Deploying image ${{ env.IMAGE_REPO }}:${{ env.IMAGE_TAG }} to EKS"
          kubectl -n ${{ env.K8S_NAMESPACE }} set image deployment/${{ env.K8S_DEPLOYMENT }} \
            ${{ env.K8S_CONTAINER }}=${{ env.IMAGE_REPO }}:${{ env.IMAGE_TAG }}

      - name: Wait for rollout
        run: |
          kubectl -n ${{ env.K8S_NAMESPACE }} rollout status deployment/${{ env.K8S_DEPLOYMENT }} --timeout=300s

      - name: Apply Kubernetes manifests
        run: |
          kubectl apply -f k8s/deployment.yaml
          kubectl apply -f k8s/service.yaml

      - name: Verify Deployment and Pods
        run: |
          kubectl -n ${{ env.K8S_NAMESPACE }} get deploy endhunger -o wide
          kubectl -n ${{ env.K8S_NAMESPACE }} get pods -l app=endhunger -o wide

      - name: Verify Service and External LB
        run: |
          kubectl -n ${{ env.K8S_NAMESPACE }} get svc endhunger-lb -o wide
          echo "External LB Hostname:"
          kubectl -n ${{ env.K8S_NAMESPACE }} get svc endhunger-lb -o jsonpath='{.status.loadBalancer.ingress[0].hostname}'; echo
